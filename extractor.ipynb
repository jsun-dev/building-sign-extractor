{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Building Sign Detection\n",
        "This notebook implements a machine perception pipeline to detect and extract building signs and their digits. Each detection is marked by a bounding box. OpenCV has been used as the computer vision library."
      ],
      "metadata": {
        "id": "lBUyrKfQ0YJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data\n",
        "The data is available for download through a public link. After downloading, unzip the folder to get access to the data."
      ],
      "metadata": {
        "id": "a9qXzsmbEYWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2bzMZUjzYoa"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# Download training and validation set\n",
        "url = 'https://drive.google.com/uc?id=1Gdxb0R8ohGqI4yB4KufWYESl0wIc8r8o'\n",
        "output = 'Data_2022_assignment_COMP3007.zip'\n",
        "gdown.download(url, output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {output} >/dev/null"
      ],
      "metadata": {
        "id": "A6VS8hkF0JzQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download testing set\n",
        "url = 'https://drive.google.com/uc?id=1vc5avjn2lRfnIDC2i7XOq22R70m6UTrH'\n",
        "output = 'Testing_Data_2022.zip'\n",
        "gdown.download(url, output)"
      ],
      "metadata": {
        "id": "R14dyGiZdHjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {output} >/dev/null"
      ],
      "metadata": {
        "id": "SC7N5_TbeBH8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Directories\n",
        "To access the data, various directories need to be defined. The data directory contains two subdirectories that correspond to the training and validation set. The test data directory contains the testing set. An output directory is also created in order to store the results of the extraction."
      ],
      "metadata": {
        "id": "yruKb9820XPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Helper function to create a directory\n",
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "# Train and valid directories\n",
        "DATA_PATH = os.path.join('Data', 'BuildingSignageDetection')\n",
        "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
        "VALID_PATH = os.path.join(DATA_PATH, 'val')\n",
        "\n",
        "# Test directory\n",
        "TEST_PATH = os.path.join('TestData', 'BuildingSignageDetection')\n",
        "\n",
        "# Output directories\n",
        "OUT_PATH = 'task1_result'\n",
        "TRAIN_OUT_PATH = os.path.join(OUT_PATH, 'train')\n",
        "VALID_OUT_PATH = os.path.join(OUT_PATH, 'val')\n",
        "TEST_OUT_PATH = os.path.join(OUT_PATH, 'test')\n",
        "\n",
        "# Create the output directories\n",
        "create_dir(OUT_PATH)\n",
        "create_dir(TRAIN_OUT_PATH)\n",
        "create_dir(VALID_OUT_PATH)\n",
        "create_dir(TEST_OUT_PATH)"
      ],
      "metadata": {
        "id": "FK1cE6q70VyV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Detection Pipeline\n",
        "A function has been created to perform the detection of the building sign. It needs a path to an image as well as an optional output path to store the result. If required, the bounding boxes can be visualized directly in the notebook.\n",
        "\n",
        "The detection pipeline can be summarised in 5 steps:\n",
        "1. Perform basic preprocessing to remove noise and standardise the image\n",
        "2. Extract blobs using connected component labeling\n",
        "3. Find digit candidates based on their dimension\n",
        "4. Filter out wrong candidates by checking the closeness of their y-coordinates\n",
        "5. Merge the contours of the digits to detect the entire building sign\n",
        "\n",
        "As the digits are defined well in the image with strong contrast and consistent dimensions, it is easier to detect them first rather than go with a sign-first approach. The building sign is harder to detect due to the potential of low contrast against shadows and dark walls. Performing the detection the other way around has proven to be successful.\n",
        "\n",
        "https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
        "\n",
        "https://pyimagesearch.com/2021/02/22/opencv-connected-component-labeling-and-analysis/\n",
        "\n",
        "https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html"
      ],
      "metadata": {
        "id": "MbE7OYFHFNRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def extract_sign(path, out_path=None, visualize=False):\n",
        "  # Create a directory to store the outputs\n",
        "  if out_path is not None:\n",
        "    file_name = path.split('/')[-1]\n",
        "    img_name = file_name.split('.')[0]\n",
        "    sign_out_path = os.path.join(out_path, img_name)\n",
        "    create_dir(sign_out_path)\n",
        "\n",
        "  # Get the image\n",
        "  img = cv2.imread(path)\n",
        "  img_copy = img.copy()\n",
        "\n",
        "  # Preprocess the image\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[-1]\n",
        "\n",
        "  # Create an empty image to store the digits\n",
        "  digits = np.zeros(thresh.shape)\n",
        "\n",
        "  # Perform blob extraction with connected component labeling\n",
        "  output = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
        "  num_labels, labels, stats, centroids = output\n",
        "\n",
        "  # Find possible digits\n",
        "  good_stats = []\n",
        "  for stat in stats:\n",
        "    # Get the dimensions\n",
        "    w, h = stat[cv2.CC_STAT_WIDTH], stat[cv2.CC_STAT_HEIGHT]\n",
        "\n",
        "    # Assume the digits are relatively small and are tall in dimension\n",
        "    if 5 <= w <= 45 and 15 <= h <= 65 and w < h:\n",
        "      good_stats.append(stat)\n",
        "\n",
        "  # Loop 3 candidates at a time to find the 3 digits of the sign\n",
        "  for i in range(len(good_stats) - 1):\n",
        "    # Get a list of 3 candidates\n",
        "    candidates = good_stats[i:i+3]\n",
        "\n",
        "    # Calculate the closeness of the candidates' y-coordinates\n",
        "    y_coords = [candidate[cv2.CC_STAT_TOP] for candidate in candidates]\n",
        "    y_coords_std = np.std(y_coords)\n",
        "\n",
        "    # Calculate the closeness of the candidates' heights\n",
        "    heights = [candidate[cv2.CC_STAT_HEIGHT] for candidate in candidates]\n",
        "    heights_std = np.std(heights)\n",
        "\n",
        "    # Extract digits if the candidates have similar y-coordinates and heights\n",
        "    if y_coords_std < 10 and heights_std < 5:\n",
        "      # Sort the digits from left to right\n",
        "      candidates = sorted(candidates, key=lambda x:int(x[cv2.CC_STAT_LEFT]))\n",
        "\n",
        "      # Extract the digits\n",
        "      for j, candidate in enumerate(candidates):\n",
        "        # Get the coordinates and dimensions\n",
        "        x, y = candidate[cv2.CC_STAT_LEFT], candidate[cv2.CC_STAT_TOP]\n",
        "        w, h = candidate[cv2.CC_STAT_WIDTH], candidate[cv2.CC_STAT_HEIGHT]\n",
        "\n",
        "        # Add the digit to the digits image\n",
        "        digit = np.zeros(thresh.shape)\n",
        "        digit[y:y+h, x:x+w] = thresh[y:y+h, x:x+w]\n",
        "        digits += digit\n",
        "\n",
        "        # Save the cropped digit\n",
        "        if out_path is not None:\n",
        "          digit_path = os.path.join(sign_out_path, 'digit{}.jpg'.format(j))\n",
        "          digit_crop = img_copy[y:y+h, x:x+w]\n",
        "          cv2.imwrite(digit_path, digit_crop)\n",
        "\n",
        "        # Draw the bounding box of the digit\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "      \n",
        "      # Stop finding more digits\n",
        "      break\n",
        "    \n",
        "  # Get all digit contours\n",
        "  digits = np.uint8(digits)\n",
        "  cnts = cv2.findContours(digits, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "\n",
        "  # Merge the contours\n",
        "  merged_cnt = []\n",
        "  for cnt in cnts:\n",
        "    for c in cnt:\n",
        "      merged_cnt.append(c)\n",
        "  merged_cnt = np.array(merged_cnt)\n",
        "\n",
        "  # Get the bounding box of the sign from the merged contour\n",
        "  x, y, w, h = cv2.boundingRect(merged_cnt)\n",
        "  w_offset, h_offset = int(w * 0.25), int(h * 0.5)\n",
        "  x -= w_offset\n",
        "  y -= h_offset\n",
        "  w += 2 * w_offset\n",
        "  h += 2 * h_offset\n",
        "\n",
        "  # Save the cropped sign\n",
        "  if out_path is not None:\n",
        "    sign_path = os.path.join(sign_out_path, 'sign.jpg')\n",
        "    sign_crop = img_copy[y:y+h, x:x+w]\n",
        "    cv2.imwrite(sign_path, sign_crop)\n",
        "\n",
        "  # Draw the bounding box of the sign\n",
        "  cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "\n",
        "  # Save the bounding box image\n",
        "  if out_path is not None:\n",
        "    print('Output of {} has been saved to {}'.format(file_name, sign_out_path))\n",
        "    boxes_path = os.path.join(sign_out_path, 'bounding_boxes.jpg')\n",
        "    cv2.imwrite(boxes_path, img)\n",
        "\n",
        "  # Visualize the bounding boxes\n",
        "  if visualize:\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "JdqA1xOg1okl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect Train Images\n",
        "This cell detects all building signs in the train subdirectory."
      ],
      "metadata": {
        "id": "pNrQCNi7IDhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_paths = sorted([os.path.join(TRAIN_PATH, img_path)\n",
        "                          for img_path in os.listdir(TRAIN_PATH)])\n",
        "\n",
        "for img_path in train_img_paths:\n",
        "  extract_sign(img_path, out_path=TRAIN_OUT_PATH, visualize=True)"
      ],
      "metadata": {
        "id": "-FVpIgr09wM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect Valid Images\n",
        "This cell detects all building signs in the valid subdirectory."
      ],
      "metadata": {
        "id": "l_UEhgyCIKVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_img_paths = sorted([os.path.join(VALID_PATH, img_path)\n",
        "                          for img_path in os.listdir(VALID_PATH)])\n",
        "\n",
        "for img_path in valid_img_paths:\n",
        "  extract_sign(img_path, out_path=VALID_OUT_PATH, visualize=True)"
      ],
      "metadata": {
        "id": "53po75tk_9yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect Test Images\n",
        "This cell detects all building signs in the test subdirectory."
      ],
      "metadata": {
        "id": "FHKzYDtVfvp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_paths = sorted([os.path.join(TEST_PATH, img_path)\n",
        "                         for img_path in os.listdir(TEST_PATH)])\n",
        "\n",
        "for img_path in test_img_paths:\n",
        "  extract_sign(img_path, out_path=TEST_OUT_PATH, visualize=True)"
      ],
      "metadata": {
        "id": "rfC5uzivfysU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect Single Image\n",
        "This cell detects a building sign from a single image."
      ],
      "metadata": {
        "id": "IiCKyNswIMns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = os.path.join(TEST_PATH, 'test04.jpg')\n",
        "extract_sign(img_path, visualize=True)"
      ],
      "metadata": {
        "id": "enB3JwnPA1_Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}